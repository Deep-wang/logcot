import pandas as pd
import os
import requests
import json
from concurrent.futures import ThreadPoolExecutor
from tenacity import retry, stop_after_attempt, wait_exponential
import re
import textwrap
from typing import List
from tqdm import tqdm
import time
import warnings
import requests
import json
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed

def File_D(file_name,api_url,OUTPUT_DIR):
    ROOT_PATH = './log'
    LOG_RELATIVE_PATH = file_name
    LOG_FILE_PATH = os.path.join(ROOT_PATH, LOG_RELATIVE_PATH)
    print(LOG_FILE_PATH)
    LINES_PER_CHUNK = 130
    MAX_WORKERS = 5
    API_KEYS = [
        "sk-dpadryupxccpbkigoduasfosszucawczlmfraqhtevaxlokx",
        "sk-kbucebwhrsoimqttlosgtxncyvmuvdyioncbadavayiovrns",
        "sk-zzuykfebwbxkurfftzuvujqpwqzxxljegnxhhwtzddvwiigf",
        "sk-qgsqryixuqdmtzkgubxpvdzollysgtonnvcrwmikwegmaogn",
        "sk-hvxqvahoplbhdadwtaomisdamxqhquvummcfpvlafeovpqus",
    ]
    log_path_sanitized = LOG_RELATIVE_PATH.replace('/', '_')
    ERROR_DIR = os.path.join(OUTPUT_DIR, log_path_sanitized + "_errors")
    os.makedirs(ERROR_DIR, exist_ok=True)
    # Scannor(LOG_FILE_PATH, LINES_PER_CHUNK, MAX_WORKERS, API_KEYS, ERROR_DIR, api_url)





@retry(stop=stop_after_attempt(7), wait=wait_exponential(multiplier=2, min=2, max=100))
def post_with_retry(payload, headers, API_URL):
    response = requests.post(API_URL, json=payload, headers=headers)
    response.raise_for_status()
    return response.json()

def analyze_log_chunk(chunk, idx, api_key, error_dir, API_URL):
    payload = {
        "model": "THUDM/GLM-4-9B-0414",
        "stream": False,
        "max_tokens": 8192,
        "enable_thinking": True,
        "thinking_budget": 4096,
        "min_p": 0.05,
        "temperature": 0,
        "top_p": 0.7,
        "top_k": 50,
        "frequency_penalty": 0.5,
        "n": 1,
        "stop": [],
        "messages": [
            {
                "role": "user",
                "content": f"æ—¥å¿—ç¬¬ {idx + 1} éƒ¨åˆ†ï¼š\n{chunk}\n\nè¯·æ˜ç¡®æ ‡æ³¨è¯¥éƒ¨åˆ†æ˜¯å¦æ­£ç¡®ï¼Œæ­£ç¡®å†™ä¸ºï¼šæ—¥å¿—æ­£ç¡®ï¼Œå¼‚å¸¸å†™ä¸ºï¼šæ—¥å¿—å¼‚å¸¸ï¼Œæ ‡æ˜é”™è¯¯æ—¶é—´å¹¶æˆªå–å‡ºç°å¼‚å¸¸ç‚¹é™„è¿‘15è¡Œæ—¥å¿—å¹¶ç»™å‡ºç®€å•è¯´æ˜"
            }
        ],
    }
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    try:
        text = post_with_retry(payload, headers, API_URL)
        result = text['choices'][0]['message']['content']
        print(f"âœ… ç¬¬ {idx + 1} å—æ—¥å¿—åˆ†æå®Œæˆ")

        if "æ—¥å¿—å¼‚å¸¸" in result:
            error_path = os.path.join(error_dir, f"error_block_{idx + 1}.txt")
            with open(error_path, "w", encoding="utf-8") as f:
                f.write("åˆ†æç»“æœï¼š\n")
                f.write(result)
            print(f"âš ï¸ å‘ç°å¼‚å¸¸ï¼Œå·²å†™å…¥ï¼š{error_path}")
        return f"ç¬¬ {idx + 1} éƒ¨åˆ†åˆ†æç»“æœï¼š\n{result}\n"

    except Exception as e:
        print(f"âŒ ç¬¬ {idx + 1} å—æ—¥å¿—åˆ†æå¤±è´¥ï¼š{e}")
        return f"ç¬¬ {idx + 1} éƒ¨åˆ†åˆ†æç»“æœï¼š\nåˆ†æå¤±è´¥ï¼š{e}\n"

def read_file_in_line_chunks(path, lines_per_chunk):
    with open(path, "r", encoding="utf-8") as f:
        lines = f.readlines()
    return ["".join(lines[i:i + lines_per_chunk]) for i in range(0, len(lines), lines_per_chunk)]

def summarize_all_chunks(all_analysis, api_key, api_url):
    summary_prompt = "\n\n".join(all_analysis)
    payload = {
        "model": "Qwen/Qwen3-8B",
        "stream": False,
        "max_tokens": 8192,
        "enable_thinking": True,
        "thinking_budget": 4096,
        "min_p": 0.05,
        "temperature": 0,
        "top_p": 0.7,
        "top_k": 50,
        "frequency_penalty": 0.5,
        "n": 1,
        "stop": [],
        "messages": [
            {
                "role": "user",
                "content": summary_prompt
            }
        ],
    }
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }

    try:
        response = post_with_retry(payload, headers, api_url)
        print("\nğŸ§¾ æœ€ç»ˆæ±‡æ€»åˆ†æç»“æœï¼š\n")
        print(response['choices'][0]['message']['content'])
    except Exception as e:
        print(f"âš ï¸ æ±‡æ€»åˆ†æå¤±è´¥ï¼š{e}")

def Scannor(log_file_path, lines_per_chunk, max_workers, api_keys, error_dir, api_url):
    chunks = read_file_in_line_chunks(log_file_path, lines_per_chunk)
    print(f"å…±è¯»å– {len(chunks)} ä¸ªæ—¥å¿—å—ï¼Œå¼€å§‹å¹¶å‘åˆ†æ...\n")
    all_analysis = []
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for idx, chunk in enumerate(chunks):
            api_key = api_keys[idx % len(api_keys)]
            futures.append(executor.submit(analyze_log_chunk, chunk, idx, api_key, error_dir, api_url))

        for future in futures:
            result = future.result()
            all_analysis.append(result)

    summarize_all_chunks(all_analysis, api_keys[0],api_url)


def UpLoad_File(dir_path):
    file_ls = []
    for root, dirs, files in os.walk(dir_path):
        root_file_ls = [os.path.join(root, file) for file in files]
        for file in root_file_ls:
            file_ls.append(file)
    file_ls1 = [file for file in file_ls if file.endswith('.DS_Store')]
    for name in file_ls1:
        file_ls.remove(name)
    return file_ls

#æ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶è¿›è¡Œåˆ†æ®µ
def fliter_Scannor(dir_path,OUTPUT_DIR):
    file_ls = UpLoad_File(dir_path)
    print(file_ls) 
    # API_URL = "https://api.siliconflow.cn/v1/chat/completions"
    # for file in file_ls:
    #     File_D(file,API_URL,OUTPUT_DIR)


# fliter_Scannor('./log/log','./Find_detect/output_529')  















def summerize_File(dir_path):
    all_text = ""
    file_ls = UpLoad_File(dir_path)
    for file in file_ls:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                all_text += f"\n--- æ–‡ä»¶ï¼š{file} ---\n"
                all_text += f.read()
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å– {file}ï¼š{e}")
    return all_text

def summerize_Scannor(dir_path,api_url,api_key):
    content = summerize_File(dir_path)
    content1 = "åˆ†æä»¥ä¸‹ä¸åŒç±»å‹é”™è¯¯æ—¥å¿—"+content+"æ€»ç»“æ—¥å¿—é”™è¯¯é¡ºåºå¹¶æ€»ç»“é”™è¯¯åŸå› "

    payload = {
        "model": "Qwen/Qwen3-8B",
        "stream": False,
        "max_tokens": 8192,
        "enable_thinking": True,
        "thinking_budget": 4096,
        "min_p": 0.05,
        "temperature": 0,
        "top_p": 0.7,
        "top_k": 50,
        "frequency_penalty": 0.5,
        "n": 1,
        "stop": [],
        "messages": [
            {
                "role": "user",
                "content": content1
            }
        ],
    }
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    try:
        response = post_with_retry(payload, headers, api_url)
        print("\nğŸ§¾ æœ€ç»ˆæ±‡æ€»åˆ†æç»“æœï¼š\n")
        print(response['choices'][0]['message']['content'])
    except Exception as e:
        print(f"âš ï¸ æ±‡æ€»åˆ†æå¤±è´¥ï¼š{e}")



File_D = ('/Users/hy_mbp/Desktop/WU/logcot/log/log/log_controller_0_Event.txt','./Find_detect/out_put_529')
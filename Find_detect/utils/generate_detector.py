from openai import OpenAI
import os

client = OpenAI(api_key="sk-YDY2HpwyWystUICYh4ui9KhI6IY3b3aDU1HRJMsrT5WLz4H2",base_url='https://api.nuwaapi.com/v1') #=== é…ç½®å‚æ•° ===

# é…ç½®é¡¹
LOG_FILE_PATH = "/log/log/123.log"
CHUNK_SIZE = 10000  # æ¯å—æœ€å¤š 10000 å­—ç¬¦ï¼Œé¿å… token è¶…é™
MODEL = "gpt-4"

def read_file_in_chunks(path, chunk_size):
    with open(path, "r", encoding="utf-8") as f:
        content = f.read()
    return [content[i:i + chunk_size] for i in range(0, len(content), chunk_size)]

def analyze_log_chunk(chunk, idx):
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æ—¥å¿—åˆ†æä¸“å®¶ï¼Œè¯·é˜…è¯»ä»¥ä¸‹æ—¥å¿—å¹¶æ‰¾å‡ºå¼‚å¸¸ã€é”™è¯¯åŸå› ã€‚"},
        {"role": "user", "content": f"æ—¥å¿—ç¬¬ {idx + 1} éƒ¨åˆ†ï¼š\n{chunk}\n\nè¯·æŒ‡å‡ºå…¶ä¸­æ˜¯å¦æœ‰é”™è¯¯æˆ–å¼‚å¸¸ï¼Œå¹¶åˆ†æåŸå› ã€‚"}
    ]
    response = client.chat.completions.create(
        model=MODEL,
        messages=messages,
        temperature=0.2
    )
    return response.choices[0].message.content

def main():
    chunks = read_file_in_chunks(LOG_FILE_PATH, CHUNK_SIZE)
    all_analysis = []

    print(f"å…±è¯»å– {len(chunks)} ä¸ªæ—¥å¿—å—ï¼Œå¼€å§‹é€ä¸ªåˆ†æ...\n")

    for idx, chunk in enumerate(chunks):
        print(f"åˆ†æç¬¬ {idx + 1} å—æ—¥å¿—...")
        analysis = analyze_log_chunk(chunk, idx)
        all_analysis.append(f"ç¬¬ {idx + 1} éƒ¨åˆ†åˆ†æç»“æœï¼š\n{analysis}\n")

    summary_prompt = "\n\n".join(all_analysis)
    print("\næ•´ç†æ±‡æ€»æ‰€æœ‰åˆ†æ...\n")

    # æ±‡æ€»æ•´ä½“åˆ†æ
    summary_messages = [
        {"role": "system", "content": "ä½ æ˜¯æ—¥å¿—åˆ†æä¸“å®¶ï¼Œè¯·æ±‡æ€»å¤šä¸ªæ—¥å¿—ç‰‡æ®µçš„åˆ†æç»“æœï¼Œæç‚¼å‡ºæ€»ä½“é”™è¯¯åŸå› åŠå»ºè®®ã€‚"},
        {"role": "user", "content": summary_prompt}
    ]

    summary = client.chat.completions.create(
        model=MODEL,
        messages=summary_messages,
        temperature=0.2
    )

    print("\nğŸ§¾ æœ€ç»ˆæ±‡æ€»åˆ†æç»“æœï¼š\n")
    print(summary.choices[0].message.content)

if __name__ == "__main__":
    main()